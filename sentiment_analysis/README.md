# Sentiment Analysis with RNN and Transformer

This project implements two deep learning approaches â€” an RNN-based model (LSTM/GRU) and a Transformer â€” to classify movie reviews from the IMDB dataset as **positive** or **negative**.

Both models are trained **from scratch** with minimal preprocessing to respect the â€œbuild from scratchâ€ requirement in the case study.

---

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ utils.py # Tokenization, vocabulary, dataset, training utilities
â”œâ”€â”€ models.py # RNNClassifier & TransformerClassifier
â”œâ”€â”€ train_sentiment.py # RNN (LSTM/GRU) training pipeline
â”œâ”€â”€ train_transformer.py # Transformer training pipeline
â”œâ”€â”€ infer_sentiment.py # Inference script
â”œâ”€â”€ sentiment_analysis_rnn_transformer.ipynb # Colab-ready notebook
â””â”€â”€ README.md # This file


---

## Requirement File

pip install -r requirements.txt 

## ğŸ“Š Dataset

I used the [Stanford IMDB Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/) containing **50,000 reviews** labeled as positive or negative.

### Download & Extract
```bash
curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
tar -xzf aclImdb_v1.tar.gz


ğŸ§  Models
1. RNN-based Classifier


Configurable embedding size, hidden size, bidirectionality

Dropout regularization

2. Transformer-based Classifier

Simple Transformer encoder

Configurable embedding size, feedforward dimension, number of layers/heads

Position encoding included

ğŸš€ Training
RNN Model
python train_sentiment.py --out_dir checkpoints_rnn --epochs 6 --batch_size 64 --rnn_type lstm --bidirectional

Transformer Model
python train_transformer.py --out_dir checkpoints_transformer --epochs 6 --batch_size 64


ğŸ” Inference

For LSTM(RNN):

python infer_sentiment.py --ckpt checkpoints_rnn/best_model.pt --text 'I loved the movie!'

Or for Transformer:

python infer_sentiment.py --ckpt checkpoints_transformer/transformer_best.pt --text 'This was amazing!'

