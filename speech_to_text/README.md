# Audio Transcription (ASR) with LibriSpeech Dummy

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ download_asr.py          # Downloads LibriSpeech dummy dataset via HuggingFace
â”œâ”€â”€ utils.py                 # Preprocessing, metrics, checkpointing
â”œâ”€â”€ models.py                # Simple ASR model (spectrogram + RNN/Transformer encoder)
â”œâ”€â”€ train_asr.py             # Training loop for ASR
â”œâ”€â”€ infer_asr.py             # Inference on audio files
â”œâ”€â”€ asr_consolidated.ipynb   # Colab-ready consolidated notebook
â””â”€â”€ README.md                # This file

## Requirement File

pip install -r requirements.txt 

## ğŸ“Š Dataset
- **Name**: `hf-internal-testing/librispeech_asr_dummy` (change to `librispeech_asr` for full set)
- **Splits**: train, validation
- **Format**: `.wav` audio files with `.txt` transcripts

RUN python download_asr.py

## ğŸ§  Model
- Simple spectrogram-based encoder-decoder
- Configurable hidden sizes, number of layers
- CTC loss for alignment-free training

## ğŸš€ Training

python train_asr.py --out_dir checkpoints_asr --epochs 10 --batch_size 8 --lr 1e-4


## ğŸ” Inference

python infer_asr.py --ckpt checkpoints_asr/asr_best.pt --audio data/SpeechCommands/SpeechCommands/speech_commands_v0.02/yes/0a7c2a8d_nohash_0.wav



